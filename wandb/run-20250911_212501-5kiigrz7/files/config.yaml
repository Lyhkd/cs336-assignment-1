_wandb:
    value:
        cli_version: 0.21.0
        e:
            djrh4o26khzigpt2ujyp8y1qw1xemi5m:
                args:
                    - --config
                    - config/lr1e3.json
                cpu_count: 72
                cpu_count_logical: 144
                cudaVersion: "12.4"
                disk:
                    /:
                        total: "4018594422784"
                        used: "3610186407936"
                email: 1362313548@qq.com
                executable: /home/yueerzhou/miniconda3/bin/python
                git:
                    commit: 8bb3a218e73cdfe622dfc6ebdb80c476b70bd770
                    remote: git@github.com:Lyhkd/cs336-assignment-1.git
                gpu: NVIDIA RTX 6000 Ada Generation
                gpu_count: 10
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-edd60fb8-4646-9355-12bd-af98019d1736
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-dcf0d006-85c1-ca38-0960-125660ed24a5
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-6f205a2b-0580-6c76-ce98-0a95cc105448
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-6ac5c8bf-c02f-3778-f815-76df61661cae
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-bea9bc0d-1fab-8723-01a6-21be4363cf74
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-e074c8b2-1844-af1c-32af-cf17ef1a2516
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-7d0cf599-3991-2169-1938-3775d4a3af0b
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-f8b515f0-69bc-be8a-0015-9141639ee661
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-72848a0a-a118-83e1-4638-4dde9cd812a9
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-6a1dff6e-17ec-d059-53e1-b21aefa744d3
                host: phe108-yuewang-01
                memory:
                    total: "2028847976448"
                os: Linux-5.15.0-124-generic-x86_64-with-glibc2.35
                program: -m cs336_basics.train
                python: CPython 3.13.2
                root: /data/yuer/assignment1-basics
                startedAt: "2025-09-12T04:25:01.214742Z"
                writerId: djrh4o26khzigpt2ujyp8y1qw1xemi5m
        m:
            - "1": step
              "6":
                - 3
              "7": []
            - "1": train/wallclock_s
              "5": 1
              "6":
                - 1
                - 3
              "7": []
        python_version: 3.13.2
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 7
                - 13
                - 16
                - 61
            "4": 3.13.2
            "5": 0.21.0
            "12": 0.21.0
            "13": linux-x86_64
batch_size:
    value: 64
checkpoint_dir:
    value: ./checkpoints
compile_model:
    value: false
config:
    value: config/lr1e3.json
context_length:
    value: 256
cosine_annealing_iters:
    value: 8000
d_ff:
    value: 1344
d_model:
    value: 512
data_dtype:
    value: uint16
dataset_name:
    value: TinyStories
device:
    value: cuda
dtype:
    value: float32
eval_data_path:
    value: data/TinyStoriesV2-GPT4-valid.txt
eval_every:
    value: 500
experiment_name:
    value: lr1e3
log_every:
    value: 50
log_file:
    value: training_lr1e3.log
max_grad_norm:
    value: 1
max_iterations:
    value: 20000
max_learning_rate:
    value: 0.001
min_learning_rate:
    value: 3e-05
num_heads:
    value: 8
num_layers:
    value: 4
resume_from:
    value: null
rope_theta:
    value: 10000
save_every:
    value: 1000
train_data_path:
    value: data/TinyStoriesV2-GPT4-train.txt
vocab_size:
    value: 10000
warmup_iters:
    value: 1000
weight_decay:
    value: 0.01
